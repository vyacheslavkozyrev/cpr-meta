---
phase: 7_test
purpose: Execute comprehensive testing to validate production readiness
applies_to: testing in cpr-api and cpr-ui feature branches
related_documents:
  - ../workflow.md
  - phase-6-review.md
  - ../../constitution.md
---

# Phase 7: Test Feature - GitHub Copilot Prompt

## User Input

```text
$ARGUMENTS
```

You **MUST** consider user input before proceeding (if not empty).

## Context

You are helping to test a feature for the CPR (Career Progress Registry) project. This is **Phase 7: Test**, where we execute comprehensive testing to ensure the feature is production-ready, meets all acceptance criteria, and maintains constitutional compliance.

**Prerequisites**:
- Phase 6 (Review) completed: Code review APPROVED with score â‰¥ 85/100
- Feature branches have passing builds and unit tests
- Test environment prepared by automation tool
- Test database configured
- API and UI running in test mode

**Your Mission**: Execute comprehensive testing strategy including integration tests, E2E tests, performance validation, security testing, and UAT. Generate detailed test report with production readiness decision.

**Automation Tool**: Before using this prompt, the user should run:
```powershell
.\framework\tools\phase-7-test.ps1 -FeatureNumber "XXXX" -FeatureName "feature-name"
```

This tool prepares the test environment, validates prerequisites, and generates `automation-test.json` with:
- Test environment status (API running, UI running, database ready)
- Unit test results summary
- Integration test results
- E2E test results
- Performance benchmark results
- Security scan results
- Test coverage metrics
- Automated test execution summary

---

## IMPORTANT: Operating Constraints

**COMPREHENSIVE TESTING**: Test all acceptance criteria, edge cases, error scenarios, and non-functional requirements.

**CONSTITUTIONAL VALIDATION**: Verify all 11 CPR Constitutional Principles are working in practice, not just in code.

**PRODUCTION SIMULATION**: Test in environment as close to production as possible.

**DOCUMENT EVERYTHING**: All test results, issues found, and resolutions must be documented.

**OBJECTIVE DECISION**: Production readiness decision must be evidence-based, not subjective.

---

## Testing Scope

### Feature Under Test
- **Feature Number**: ####
- **Feature Name**: [from specification]
- **Feature Branches**: 
  - Backend: `feature/####-<name>` in cpr-api
  - Frontend: `feature/####-<name>` in cpr-ui

### Documents to Reference
1. `description.md` - Acceptance criteria and requirements
2. `implementation-plan.md` - Technical architecture
3. `review-report.md` - Code review findings
4. `automation-test.json` - Automated test results
5. `test-plan.md` - Test scenarios (generated by tool)

### Constitutional Principles to Validate
All 11 principles must be tested in practice:
1. Specification-Driven: Feature matches specification
2. API Contract Consistency: DTOs work correctly
3. Framework Integration: Patterns work as expected
4. Type Safety: No runtime type errors
5. Offline-First: Offline mode functions correctly
6. Internationalization: Multiple locales work
7. Comprehensive Testing: This phase validates this principle
8. Performance Standards: Meets <200ms API, <1s UI targets
9. Naming Conventions: Validated in review, working in practice
10. Security First: Authentication, authorization work correctly
11. Database Standards: Data integrity maintained

---

## Testing Workflow

### Step 1: Load Test Context

**First, read `automation-test.json`** (generated by phase-7-test.ps1):

The automation tool has already:
- âœ… Validated Phase 6 APPROVED status
- âœ… Started test environment (API, UI, database)
- âœ… Run unit tests and collected results
- âœ… Run integration tests
- âœ… Run E2E tests (if configured)
- âœ… Collected performance metrics
- âœ… Run security scans
- âœ… Calculated test coverage

**Review automated test results**:
- Check all unit tests passed
- Review integration test results
- Note any E2E test failures
- Check performance benchmarks
- Review security scan findings

**Your testing focuses on**:
- Validating acceptance criteria manually
- Testing edge cases not covered by automation
- User experience and usability testing
- Cross-browser and responsive testing
- User acceptance testing (UAT)
- Production readiness assessment

---

### Step 2: Validate Test Environment

**Verify Environment Ready**:
- [ ] Backend API running and responsive
- [ ] Frontend UI accessible in browser
- [ ] Test database populated with test data
- [ ] Authentication working
- [ ] Network requests successful

**Check `automation-test.json` for**:
- Test environment status: READY/NOT_READY
- API health check: PASS/FAIL
- UI health check: PASS/FAIL
- Database connection: PASS/FAIL

**If environment not ready**:
- Review automation tool output for errors
- Fix environment issues
- Re-run automation tool
- Stop testing until environment is READY

---

### Step 3: Integration Testing

**Backend Integration Tests**:

Review automated integration test results from `automation-test.json`, then perform manual validation:

**For Each API Endpoint** (from endpoints.md):
1. **Happy Path Testing**:
   - [ ] Send valid request with all required fields
   - [ ] Verify correct response status (200, 201, 204)
   - [ ] Validate response body matches schema
   - [ ] Confirm data persisted to database
   - [ ] Check audit fields (created_at, updated_at)

2. **Authentication Testing**:
   - [ ] Request without token returns 401 Unauthorized
   - [ ] Request with invalid token returns 401
   - [ ] Request with valid token succeeds

3. **Authorization Testing**:
   - [ ] User without permission returns 403 Forbidden
   - [ ] User with correct role succeeds
   - [ ] Cross-user data access blocked

4. **Validation Testing**:
   - [ ] Missing required fields returns 400 Bad Request
   - [ ] Invalid data types returns 400
   - [ ] Validation error messages clear and helpful
   - [ ] Business rule violations return appropriate error

5. **Error Scenario Testing**:
   - [ ] Non-existent resource returns 404 Not Found
   - [ ] Duplicate resource returns 409 Conflict (if applicable)
   - [ ] Server errors return 500 with safe message

6. **Data Integrity Testing**:
   - [ ] Foreign key constraints enforced
   - [ ] Unique constraints enforced
   - [ ] Check constraints enforced
   - [ ] Soft delete works correctly (is_deleted flag)

**Database Integration**:
- [ ] Migrations applied successfully
- [ ] All tables, indexes, constraints created
- [ ] No N+1 query problems (check logs)
- [ ] Transactions work correctly (rollback on error)

**External Service Integration** (if applicable):
- [ ] Service connections work
- [ ] Error handling for unavailable services
- [ ] Timeout handling
- [ ] Retry logic (if implemented)

**Integration Test Results**:
- Document pass/fail for each endpoint
- Note any issues found
- Verify fixes if issues resolved
- Calculate endpoint test coverage (should be 100%)

---

### Step 4: End-to-End (E2E) Testing

**Critical User Journeys**:

For each user story in description.md, test the complete workflow:

**Example E2E Test Flow**:
1. **Setup**: User authenticated, starting state prepared
2. **Action**: User performs actions through UI
3. **Verification**: Expected outcomes achieved
4. **Cleanup**: Return to clean state

**For Each User Story**:
- [ ] Test happy path (all steps succeed)
- [ ] Test error scenarios (validation failures, conflicts)
- [ ] Test edge cases (boundary conditions, empty states)
- [ ] Test multi-step workflows
- [ ] Test back button and navigation
- [ ] Test form submission and validation
- [ ] Test loading states and error messages
- [ ] Test success confirmations

**Cross-Feature Testing**:
- [ ] Test interactions with existing features
- [ ] Test data consistency across features
- [ ] Test navigation between features
- [ ] Test shared components

**Browser Compatibility**:
Test in multiple browsers:
- [ ] Chrome (latest)
- [ ] Firefox (latest)
- [ ] Edge (latest)
- [ ] Safari (if applicable)

**Responsive Design**:
Test at different viewport sizes:
- [ ] Desktop (1920x1080)
- [ ] Laptop (1366x768)
- [ ] Tablet (768x1024)
- [ ] Mobile (375x667)

**E2E Test Results**:
- Document each user journey tested
- Note pass/fail status
- Screenshot or record failures
- Verify all acceptance criteria met
- Calculate E2E coverage (all critical journeys)

---

### Step 5: Performance Testing

**Review automated performance metrics from `automation-test.json`**, then validate:

**API Performance**:
For each endpoint:
- [ ] Measure response time (target: <200ms)
- [ ] Test with realistic data volumes
- [ ] Check 95th percentile response time
- [ ] Verify no memory leaks
- [ ] Check database query performance

**Performance Benchmarks**:
```
Endpoint: GET /api/v1/users/{id}
- Average: XXms
- 95th percentile: XXms
- 99th percentile: XXms
- Target: <200ms
- Status: PASS/FAIL
```

**UI Performance**:
- [ ] Initial page load time (<2s)
- [ ] Time to interactive (<3s)
- [ ] Button click response (<100ms)
- [ ] Form submission response (<1s)
- [ ] Navigation response (<500ms)
- [ ] List rendering with 100+ items

**Bundle Size**:
- [ ] Initial bundle size (<500KB gzipped)
- [ ] Lazy-loaded chunks appropriately sized
- [ ] No duplicate dependencies

**Load Testing** (if applicable):
- [ ] Test with 10 concurrent users
- [ ] Test with 50 concurrent users
- [ ] Verify response times stable under load
- [ ] Check server resource usage

**Performance Test Results**:
- Document all measurements
- Compare against targets
- Identify bottlenecks if targets not met
- Recommend optimizations

---

### Step 6: Security Testing

**Review automated security scan from `automation-test.json`**, then perform manual security testing:

**Authentication Flow**:
- [ ] Login with valid credentials succeeds
- [ ] Login with invalid credentials fails
- [ ] Password requirements enforced
- [ ] JWT token includes correct claims
- [ ] Token expiration works
- [ ] Token refresh works (if implemented)
- [ ] Logout clears authentication

**Authorization Enforcement**:
Test for each protected resource:
- [ ] Unauthenticated access returns 401
- [ ] Unauthorized access returns 403
- [ ] Role-based access works correctly
- [ ] Policy-based access works correctly
- [ ] Cross-user data access blocked
- [ ] Admin-only features protected

**Input Validation**:
- [ ] XSS attempts blocked (script injection)
- [ ] SQL injection attempts blocked
- [ ] Path traversal blocked
- [ ] File upload validation (if applicable)
- [ ] Max length validation
- [ ] Special character handling

**Data Protection**:
- [ ] No sensitive data in logs
- [ ] No passwords in error messages
- [ ] No PII in URLs
- [ ] HTTPS enforced (in production config)
- [ ] CORS policy correct
- [ ] Security headers present

**Common Vulnerabilities**:
- [ ] No hardcoded secrets
- [ ] No exposed API keys
- [ ] No default credentials
- [ ] No verbose error messages in production
- [ ] Dependencies up to date (no CVEs)

**Security Test Results**:
- List all security tests performed
- Document any vulnerabilities found
- Severity rating (CRITICAL/HIGH/MEDIUM/LOW)
- Remediation status
- Re-test after fixes

---

### Step 7: Offline Mode Testing (Constitutional Principle 5)

**Offline Data Access**:
- [ ] Access cached data while offline
- [ ] UI shows offline indicator
- [ ] Read operations work from cache
- [ ] Write operations queue for sync

**Optimistic Updates**:
- [ ] UI updates immediately on user action
- [ ] Data syncs when connection restored
- [ ] Conflict detection works
- [ ] Conflict resolution correct

**IndexedDB Caching**:
- [ ] Critical data cached to IndexedDB
- [ ] Cache invalidation works
- [ ] Cache size reasonable
- [ ] Old data cleaned up

**React Query Persistence**:
- [ ] Query cache persists across page reloads
- [ ] Stale data handled correctly
- [ ] Background refetch works

**Sync Conflict Resolution**:
- [ ] Detect conflicts (last-write-wins or custom)
- [ ] User notified of conflicts
- [ ] Resolution strategy works correctly

**Offline Test Results**:
- Document all offline scenarios tested
- Verify offline-first principle implemented
- Note any sync issues

---

### Step 8: Internationalization Testing (Constitutional Principle 6)

**Multiple Locale Testing**:

Test with at least 2-3 locales (e.g., en, es, fr):

**UI Text Internationalization**:
- [ ] No hardcoded English strings in UI
- [ ] All text uses i18n keys
- [ ] Missing translation keys handled gracefully
- [ ] Language switcher works
- [ ] Language persists across sessions

**Date/Time Formatting**:
- [ ] Dates formatted per locale (MM/DD/YYYY vs DD/MM/YYYY)
- [ ] Time formatted per locale (12h vs 24h)
- [ ] Timezone handling correct
- [ ] Relative dates ("2 hours ago") localized

**Number/Currency Formatting**:
- [ ] Numbers formatted per locale (1,000 vs 1.000)
- [ ] Decimal separator correct (. vs ,)
- [ ] Currency symbol correct
- [ ] Currency amounts formatted correctly

**RTL Language Support** (if applicable):
- [ ] Layout adjusts for RTL (Arabic, Hebrew)
- [ ] Text alignment correct
- [ ] Icons/images mirrored appropriately

**i18n Test Results**:
- Document locales tested
- List any missing translations
- Note formatting issues
- Verify Constitutional Principle 6 compliance

---

### Step 9: Accessibility Testing

**Keyboard Navigation**:
- [ ] All interactive elements accessible via Tab
- [ ] Tab order logical
- [ ] Enter/Space activate buttons/links
- [ ] Escape closes modals
- [ ] Arrow keys navigate lists/menus
- [ ] No keyboard traps

**Screen Reader Testing**:
Use screen reader (NVDA, JAWS, or built-in):
- [ ] All content readable
- [ ] Interactive elements announced correctly
- [ ] Form labels associated with inputs
- [ ] Error messages announced
- [ ] Dynamic content updates announced
- [ ] Skip links present

**ARIA Attributes**:
- [ ] ARIA labels on icon buttons
- [ ] ARIA roles appropriate
- [ ] ARIA live regions for dynamic content
- [ ] ARIA expanded/pressed states correct
- [ ] ARIA invalid for form errors

**Color Contrast**:
- [ ] Text contrast â‰¥4.5:1 (WCAG AA)
- [ ] Large text contrast â‰¥3:1
- [ ] Interactive elements contrast â‰¥3:1
- [ ] No information by color alone

**Focus Management**:
- [ ] Focus visible indicator
- [ ] Focus moved to modals on open
- [ ] Focus returned on modal close
- [ ] Focus not lost on navigation

**Accessibility Test Results**:
- Use browser DevTools Lighthouse
- Run axe accessibility scanner
- Document WCAG 2.1 AA compliance level
- List accessibility issues and fixes

---

### Step 10: User Acceptance Testing (UAT)

**Stakeholder Walkthrough**:

Prepare demo environment and walk stakeholders through:

**For Each User Story**:
1. **Explain Context**:
   - Show user story from description.md
   - Explain acceptance criteria
   - Describe implementation approach

2. **Demonstrate Functionality**:
   - Walk through happy path
   - Show error handling
   - Demonstrate edge cases
   - Show responsiveness and accessibility

3. **Gather Feedback**:
   - Does it meet requirements?
   - Are interactions intuitive?
   - Are error messages clear?
   - Any missing functionality?
   - Any suggestions for improvement?

4. **Document Decision**:
   - APPROVED: Meets requirements
   - APPROVED WITH CHANGES: Minor improvements needed
   - REJECTED: Does not meet requirements

**Acceptance Criteria Validation**:
For each acceptance criterion in description.md:
- [ ] Demonstrate criterion met
- [ ] Stakeholder confirms
- [ ] Document approval

**Business Rules Validation**:
For each business rule in description.md:
- [ ] Demonstrate rule enforced
- [ ] Test violation scenarios
- [ ] Stakeholder confirms correct behavior

**UAT Results**:
- Document stakeholder feedback
- List approved user stories
- Note required changes
- Get sign-off (APPROVED/CONDITIONAL/REJECTED)

---

### Step 11: Calculate Test Score

**Scoring System**:

Start with **100 points**, deduct based on test results:

**Test Execution** (40 points):
- Integration tests: -20 if any fail
- E2E tests: -20 if critical journeys fail
- Score: XX/40

**Performance** (20 points):
- API performance: -10 if >200ms (95th percentile)
- UI performance: -10 if >1s interactions
- Score: XX/20

**Security** (20 points):
- CRITICAL vulnerability: -20 (automatic fail)
- HIGH vulnerability: -15
- MEDIUM vulnerability: -5
- Score: XX/20

**Non-Functional** (20 points):
- Offline mode: -5 if not working
- i18n: -5 if not complete
- Accessibility: -5 if < WCAG AA
- UAT: -5 if not approved
- Score: XX/20

**Final Test Score**: Sum of all categories (0-100)

**Production Readiness Status**:
- **â‰¥90/100**: âœ… READY
- **75-89/100**: âš ï¸ CONDITIONAL
- **<75/100 or CRITICAL security**: âŒ NOT READY

---

### Step 12: Generate Test Report

**Create `test-report.md` in specification folder**:

**Report Structure**:

```markdown
# Phase 7: Test Report

**Feature**: ####-feature-name
**Test Date**: YYYY-MM-DD
**Tester**: [Your name or "GitHub Copilot AI-assisted"]
**Production Readiness**: âœ… READY | âš ï¸ CONDITIONAL | âŒ NOT READY

---

## Executive Summary

[2-3 paragraph summary of testing outcomes]

**Overall Assessment**: [Summary of test quality and readiness]

**Test Coverage**: 
- Unit Tests: X% coverage
- Integration Tests: Y/Y endpoints tested
- E2E Tests: Z/Z critical journeys tested

**Issues Found**: X total (CRITICAL: 0, HIGH: 0, MEDIUM: 0, LOW: 0)

**Final Test Score**: XX/100

**Production Readiness**: âœ… READY | âš ï¸ CONDITIONAL | âŒ NOT READY

**Reasoning**: [1-2 sentences explaining the decision]

---

## Test Execution Summary

| Category | Tests Run | Passed | Failed | Skipped | Coverage | Status |
|----------|-----------|--------|--------|---------|----------|--------|
| Unit Tests (API) | X | X | 0 | 0 | XX% | âœ… |
| Unit Tests (UI) | X | X | 0 | 0 | XX% | âœ… |
| Integration Tests | X | X | 0 | 0 | 100% | âœ… |
| E2E Tests | X | X | 0 | 0 | 100% | âœ… |
| Performance Tests | X | X | 0 | 0 | - | âœ… |
| Security Tests | X | X | 0 | 0 | - | âœ… |
| Accessibility Tests | X | X | 0 | 0 | - | âœ… |
| **Total** | **X** | **X** | **0** | **0** | **XX%** | **âœ…** |

---

## Integration Test Results

[For each API endpoint from endpoints.md]

### Endpoint: POST /api/v1/resource

**Status**: âœ… PASS | âŒ FAIL

**Tests Executed**:
- âœ… Happy path with valid data
- âœ… Authentication required (401 without token)
- âœ… Authorization enforced (403 for unauthorized user)
- âœ… Validation errors (400 for invalid data)
- âœ… Resource created in database
- âœ… Audit fields populated

**Response Time**: XXms (target: <200ms)

**Issues**: None | [List issues if any]

---

## E2E Test Results

[For each user story]

### User Story: US-001 - [Title]

**Status**: âœ… PASS | âŒ FAIL

**Test Scenarios**:
1. âœ… Happy path: User completes workflow successfully
2. âœ… Error handling: Validation errors shown correctly
3. âœ… Edge case: Empty state handled
4. âœ… Navigation: Back button works correctly

**Acceptance Criteria**:
- âœ… AC1: [Criterion description] - VERIFIED
- âœ… AC2: [Criterion description] - VERIFIED
- âœ… AC3: [Criterion description] - VERIFIED

**Browser Compatibility**:
- âœ… Chrome: All tests pass
- âœ… Firefox: All tests pass
- âœ… Edge: All tests pass

**Responsive Design**:
- âœ… Desktop (1920x1080)
- âœ… Tablet (768x1024)
- âœ… Mobile (375x667)

**Issues**: None | [List issues if any]

---

## Performance Test Results

### API Performance

| Endpoint | Avg (ms) | 95th (ms) | 99th (ms) | Target | Status |
|----------|----------|-----------|-----------|--------|--------|
| GET /api/v1/resource | XX | XX | XX | <200ms | âœ… |
| POST /api/v1/resource | XX | XX | XX | <200ms | âœ… |
| PUT /api/v1/resource/{id} | XX | XX | XX | <200ms | âœ… |
| DELETE /api/v1/resource/{id} | XX | XX | XX | <200ms | âœ… |

**Database Performance**:
- âœ… No N+1 queries detected
- âœ… All queries use proper indexes
- âœ… Query execution times acceptable

### UI Performance

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Initial Load Time | X.Xs | <2s | âœ… |
| Time to Interactive | X.Xs | <3s | âœ… |
| Button Click Response | XXms | <100ms | âœ… |
| Form Submit Response | XXXms | <1s | âœ… |
| Navigation Response | XXms | <500ms | âœ… |

**Bundle Size**:
- Initial Bundle: XXX KB (gzipped)
- Target: <500KB
- Status: âœ… PASS | âŒ FAIL

**Load Testing** (if applicable):
- 10 concurrent users: âœ… Stable
- 50 concurrent users: âœ… Stable
- Performance degradation: None | XX%

---

## Security Test Results

### Authentication

- âœ… Login flow works correctly
- âœ… Invalid credentials rejected
- âœ… JWT token valid and contains correct claims
- âœ… Token expiration enforced
- âœ… Logout clears authentication

### Authorization

- âœ… Unauthenticated access returns 401
- âœ… Unauthorized access returns 403
- âœ… Role-based access control works
- âœ… Cross-user data access blocked

### Input Validation

- âœ… XSS prevention working
- âœ… SQL injection prevention working
- âœ… Path traversal blocked
- âœ… Max length validation enforced

### Data Protection

- âœ… No sensitive data in logs
- âœ… No PII in URLs
- âœ… HTTPS enforced (production config)
- âœ… Security headers present

### Vulnerability Scan

**Automated Scan Results**:
- CRITICAL: 0
- HIGH: 0
- MEDIUM: 0
- LOW: 0

**Status**: âœ… No vulnerabilities found | âš ï¸ See findings below

[If vulnerabilities found, list with severity, description, remediation]

---

## Offline Mode Test Results (Principle 5)

- âœ… Data accessible while offline
- âœ… UI shows offline indicator
- âœ… Optimistic updates work
- âœ… Sync works when connection restored
- âœ… Conflict resolution works correctly
- âœ… IndexedDB caching functional
- âœ… React Query persistence working

**Status**: âœ… PASS | âŒ FAIL

---

## Internationalization Test Results (Principle 6)

**Locales Tested**: en-US, es-ES, fr-FR

- âœ… All UI text uses i18n keys (no hardcoded strings)
- âœ… Language switcher works
- âœ… Date/time formatting correct per locale
- âœ… Number/currency formatting correct per locale
- âœ… Missing translation keys handled gracefully

**Status**: âœ… PASS | âŒ FAIL

---

## Accessibility Test Results

### WCAG 2.1 Compliance

- âœ… Level A: Compliant
- âœ… Level AA: Compliant
- âš ï¸ Level AAA: Partial (not required)

### Lighthouse Accessibility Score

- Score: XX/100
- Target: â‰¥90
- Status: âœ… PASS | âŒ FAIL

### axe DevTools Scan

- CRITICAL: 0
- SERIOUS: 0
- MODERATE: 0
- MINOR: 0

### Manual Testing

- âœ… Keyboard navigation complete
- âœ… Screen reader compatible
- âœ… Color contrast meets WCAG AA
- âœ… Focus management correct
- âœ… ARIA attributes appropriate

**Status**: âœ… PASS | âŒ FAIL

---

## User Acceptance Testing (UAT)

**Stakeholder**: [Name/Role]
**UAT Date**: YYYY-MM-DD

### User Stories Validated

| Story | Title | Status | Feedback |
|-------|-------|--------|----------|
| US-001 | [Title] | âœ… APPROVED | [Comments] |
| US-002 | [Title] | âœ… APPROVED | [Comments] |
| US-003 | [Title] | âš ï¸ CONDITIONAL | [Required changes] |

### Overall UAT Decision

**Status**: âœ… APPROVED | âš ï¸ APPROVED WITH CHANGES | âŒ REJECTED

**Feedback Summary**:
- [Positive feedback 1]
- [Positive feedback 2]
- [Concern or change request 1]
- [Concern or change request 2]

**Required Changes** (if CONDITIONAL):
1. [Change 1]
2. [Change 2]

---

## Issues Found

[If issues found during testing]

### Issue #1: [Title]

- **Severity**: CRITICAL | HIGH | MEDIUM | LOW
- **Category**: [Integration/E2E/Performance/Security/Accessibility]
- **Description**: [What's wrong]
- **Steps to Reproduce**: 
  1. [Step 1]
  2. [Step 2]
- **Expected**: [What should happen]
- **Actual**: [What actually happens]
- **Resolution**: [How it was fixed]
- **Status**: âœ… FIXED | âš ï¸ WORKAROUND | âŒ OPEN

---

## Test Score Calculation

### Category Scores

**Test Execution** (40 points):
- Integration tests: 20/20 (all passed)
- E2E tests: 20/20 (all critical journeys passed)
- **Subtotal**: 40/40

**Performance** (20 points):
- API performance: 10/10 (<200ms)
- UI performance: 10/10 (<1s)
- **Subtotal**: 20/20

**Security** (20 points):
- No CRITICAL vulnerabilities: 20/20
- **Subtotal**: 20/20

**Non-Functional** (20 points):
- Offline mode: 5/5
- i18n: 5/5
- Accessibility: 5/5
- UAT: 5/5
- **Subtotal**: 20/20

### Final Score

**Total Score**: 100/100

**Deductions**: 
- [None] | [List any deductions with reasons]

---

## Production Readiness Decision

### Decision: âœ… READY | âš ï¸ CONDITIONAL | âŒ NOT READY

### Justification

[Detailed explanation of decision based on test results]

**If READY**:
- All tests pass
- Performance targets met
- No security vulnerabilities
- UAT approved
- Ready for Phase 8 (Deploy)

**If CONDITIONAL**:
- Minor issues found: [list]
- Workarounds in place: [list]
- Monitoring plan: [describe]
- Can deploy with close observation

**If NOT READY**:
- Blocking issues: [list]
- Must fix before deployment
- Retest required after fixes

---

## Recommendations

**Before Deployment**:
1. [Recommendation 1]
2. [Recommendation 2]

**Post-Deployment Monitoring**:
1. [What to monitor]
2. [Alert thresholds]

**Future Improvements**:
1. [Nice-to-have enhancement]
2. [Performance optimization]

---

## Test Artifacts

**Available Artifacts**:
- Test execution logs: [location]
- E2E test recordings: [location]
- Performance benchmark reports: [location]
- Security scan reports: [location]
- Accessibility audit reports: [location]
- UAT sign-off: [document location]

---

## Next Steps

**If READY (â‰¥90/100)**:
1. âœ… Proceed to Phase 8: Deploy
2. Merge feature branches to main/develop
3. Prepare deployment checklist
4. Schedule deployment window

**If CONDITIONAL (75-89/100)**:
1. âš ï¸ Address identified issues
2. Implement workarounds/monitoring
3. Get stakeholder approval for conditional deployment
4. Proceed to Phase 8 with caution

**If NOT READY (<75/100)**:
1. âŒ Fix all CRITICAL and HIGH issues
2. Re-run affected tests
3. Re-evaluate production readiness
4. Phase 8 BLOCKED until READY

---

**Test Report Complete** âœ“

[End of Test Report]
```

---

## Quality Checklist

Before finalizing test report:

- [ ] All automated test results from automation-test.json reviewed
- [ ] All integration tests executed and documented
- [ ] All E2E tests for critical journeys executed
- [ ] Performance benchmarks meet targets (<200ms API, <1s UI)
- [ ] Security testing complete with no HIGH/CRITICAL vulnerabilities
- [ ] Offline mode tested and working
- [ ] i18n tested with multiple locales
- [ ] Accessibility meets WCAG 2.1 AA
- [ ] UAT completed with stakeholder sign-off
- [ ] All acceptance criteria validated
- [ ] Test score calculated correctly (0-100)
- [ ] Production readiness decision justified
- [ ] All issues documented with severity and resolution
- [ ] Recommendations provided for deployment and monitoring
- [ ] Report saved to specifications/####-<feature-name>/test-report.md
- [ ] progress.md updated with Phase 7 status

---

## Important Notes

**Be Thorough**:
- Test all acceptance criteria exhaustively
- Don't skip edge cases or error scenarios
- Document everything, even if tests pass

**Be Objective**:
- Base production readiness on evidence, not gut feeling
- Don't downplay issues to meet deadlines
- Stakeholder pressure doesn't change test results

**Be Clear**:
- Test results should be unambiguous (PASS/FAIL)
- Issues should be clearly described with reproduction steps
- Recommendations should be specific and actionable

**Be Realistic**:
- Not every feature needs to be perfect
- CONDITIONAL (75-89) allows staging deployment for additional validation
- READY (â‰¥90) required for production deployment
- Balance quality with business needs

---

## Next Phase

**Upon completion of Phase 7 Testing**:

- **If READY (â‰¥90/100)**: Proceed to **Phase 8 (Deploy)** for production deployment
- **If CONDITIONAL (75-89)**: Deploy to staging, fix issues, re-test to reach READY before production
- **If NOT READY (<75)**: Return to **Phase 5 (Implement)** or **Phase 6 (Review)** to fix issues

**Phase 8 Prerequisites**:
- âœ… `test-report.md` generated with READY or CONDITIONAL status
- âœ… `automation-test.json` with comprehensive test results
- âœ… All CRITICAL issues resolved
- âœ… UAT approval obtained from stakeholders
- âœ… Production readiness score â‰¥75/100

**To start Phase 8**:
```powershell
.\framework\tools\phase-8-deploy.ps1 -FeatureNumber "####" -FeatureName "feature-name" -Environment "staging"
```

Then use AI prompt: `framework/prompts/phase-8-deploy.md`

---

**Good luck with testing! ðŸ§ª**
